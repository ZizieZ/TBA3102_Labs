{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state: 1559518326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import tba3102\n",
    "import model_evaluation_utils as meu\n",
    "\n",
    "\n",
    "\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "tba3102.set_default_pandas_options()\n",
    "\n",
    "np.random.seed(int(round(time.time())))\n",
    "random_state = 1559518326 # np.random.randint(2**31-1)\n",
    "print('random_state: {}'.format(random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model, train_features, train_label, test_features, test_label):\n",
    "    \n",
    "    model.fit(train_features, train_label)\n",
    "    cv_scores = cross_val_score(model, train_features, train_label, cv=5)\n",
    "    cv_mean_score = np.mean(cv_scores)\n",
    "\n",
    "    print('Training Accuracy (5-fold):', cv_scores)\n",
    "    print('Mean Training Accuracy:', cv_mean_score)\n",
    "    \n",
    "    test_score = model.score(test_features, test_label)\n",
    "    print('Testing Accuracy:', test_score)\n",
    "    \n",
    "    predictions = model.predict(test_features)\n",
    "    unique_classes = list(set(test_label))\n",
    "    \n",
    "    meu.get_metrics(true_labels=test_label, predicted_labels=predictions)\n",
    "    \n",
    "    meu.display_classification_report(true_labels=test_label, predicted_labels=predictions, classes=unique_classes)\n",
    "    \n",
    "    print(metrics.confusion_matrix(y_true=test_label, y_pred=predictions, labels=unique_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing started at 2023-04-04 20:41:44.534984\n"
     ]
    }
   ],
   "source": [
    "print('Text processing started at {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without_emoticon BOW-TF Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.73380974 0.73604288 0.74542206 0.73023671 0.73023671]\n",
      "Mean Training Accuracy: 0.7351496203662349\n",
      "Testing Accuracy: 0.7447384871848302\n",
      "Accuracy: 0.7447\n",
      "Precision: 0.7452\n",
      "Recall: 0.7447\n",
      "F1 Score: 0.7446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.72      0.74      2399\n",
      "    positive       0.73      0.77      0.75      2400\n",
      "\n",
      "    accuracy                           0.74      4799\n",
      "   macro avg       0.75      0.74      0.74      4799\n",
      "weighted avg       0.75      0.74      0.74      4799\n",
      "\n",
      "[[1735  664]\n",
      " [ 561 1839]]\n",
      "================================================================================\n",
      "without_emoticon BOW-TF Support Vector Machines\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.72711032 0.7172845  0.74542206 0.72085753 0.7204109 ]\n",
      "Mean Training Accuracy: 0.7262170611880304\n",
      "Testing Accuracy: 0.7314023754948947\n",
      "Accuracy: 0.7314\n",
      "Precision: 0.7316\n",
      "Recall: 0.7314\n",
      "F1 Score: 0.7313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.72      0.73      2399\n",
      "    positive       0.72      0.75      0.74      2400\n",
      "\n",
      "    accuracy                           0.73      4799\n",
      "   macro avg       0.73      0.73      0.73      4799\n",
      "weighted avg       0.73      0.73      0.73      4799\n",
      "\n",
      "[[1719  680]\n",
      " [ 609 1791]]\n",
      "================================================================================\n",
      "without_emoticon BOW-TFIDF Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.73470299 0.73693613 0.75212148 0.74140241 0.73336311]\n",
      "Mean Training Accuracy: 0.7397052255471193\n",
      "Testing Accuracy: 0.7432798499687435\n",
      "Accuracy: 0.7433\n",
      "Precision: 0.7435\n",
      "Recall: 0.7433\n",
      "F1 Score: 0.7432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.76      0.75      2399\n",
      "    positive       0.75      0.73      0.74      2400\n",
      "\n",
      "    accuracy                           0.74      4799\n",
      "   macro avg       0.74      0.74      0.74      4799\n",
      "weighted avg       0.74      0.74      0.74      4799\n",
      "\n",
      "[[1822  577]\n",
      " [ 655 1745]]\n",
      "================================================================================\n",
      "without_emoticon BOW-TFIDF Support Vector Machines\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.72755695 0.73604288 0.75658776 0.72532381 0.73782939]\n",
      "Mean Training Accuracy: 0.7366681554265297\n",
      "Testing Accuracy: 0.7461971244009169\n",
      "Accuracy: 0.7462\n",
      "Precision: 0.7467\n",
      "Recall: 0.7462\n",
      "F1 Score: 0.7461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.77      0.75      2399\n",
      "    positive       0.76      0.72      0.74      2400\n",
      "\n",
      "    accuracy                           0.75      4799\n",
      "   macro avg       0.75      0.75      0.75      4799\n",
      "weighted avg       0.75      0.75      0.75      4799\n",
      "\n",
      "[[1842  557]\n",
      " [ 661 1739]]\n",
      "================================================================================\n",
      "with_emoticon BOW-TF Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.73258929 0.75       0.75133929 0.734375   0.7476552 ]\n",
      "Mean Training Accuracy: 0.7431917549288587\n",
      "Testing Accuracy: 0.7441666666666666\n",
      "Accuracy: 0.7442\n",
      "Precision: 0.7444\n",
      "Recall: 0.7442\n",
      "F1 Score: 0.7441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.73      0.74      2400\n",
      "    positive       0.74      0.76      0.75      2400\n",
      "\n",
      "    accuracy                           0.74      4800\n",
      "   macro avg       0.74      0.74      0.74      4800\n",
      "weighted avg       0.74      0.74      0.74      4800\n",
      "\n",
      "[[1751  649]\n",
      " [ 579 1821]]\n",
      "================================================================================\n",
      "with_emoticon BOW-TF Support Vector Machines\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.73303571 0.734375   0.73214286 0.71964286 0.73559625]\n",
      "Mean Training Accuracy: 0.7309585353793147\n",
      "Testing Accuracy: 0.7314583333333333\n",
      "Accuracy: 0.7315\n",
      "Precision: 0.7316\n",
      "Recall: 0.7315\n",
      "F1 Score: 0.7314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.72      0.73      2400\n",
      "    positive       0.73      0.74      0.73      2400\n",
      "\n",
      "    accuracy                           0.73      4800\n",
      "   macro avg       0.73      0.73      0.73      4800\n",
      "weighted avg       0.73      0.73      0.73      4800\n",
      "\n",
      "[[1729  671]\n",
      " [ 618 1782]]\n",
      "================================================================================\n",
      "with_emoticon BOW-TFIDF Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.74330357 0.75714286 0.75044643 0.73258929 0.74050916]\n",
      "Mean Training Accuracy: 0.7447982597460601\n",
      "Testing Accuracy: 0.744375\n",
      "Accuracy: 0.7444\n",
      "Precision: 0.7448\n",
      "Recall: 0.7444\n",
      "F1 Score: 0.7443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75      2400\n",
      "    positive       0.76      0.72      0.74      2400\n",
      "\n",
      "    accuracy                           0.74      4800\n",
      "   macro avg       0.74      0.74      0.74      4800\n",
      "weighted avg       0.74      0.74      0.74      4800\n",
      "\n",
      "[[1837  563]\n",
      " [ 664 1736]]\n",
      "================================================================================\n",
      "with_emoticon BOW-TFIDF Support Vector Machines\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.73928571 0.74553571 0.74553571 0.73080357 0.74363555]\n",
      "Mean Training Accuracy: 0.7409592531742488\n",
      "Testing Accuracy: 0.743125\n",
      "Accuracy: 0.7431\n",
      "Precision: 0.744\n",
      "Recall: 0.7431\n",
      "F1 Score: 0.7429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75      2400\n",
      "    positive       0.76      0.71      0.74      2400\n",
      "\n",
      "    accuracy                           0.74      4800\n",
      "   macro avg       0.74      0.74      0.74      4800\n",
      "weighted avg       0.74      0.74      0.74      4800\n",
      "\n",
      "[[1856  544]\n",
      " [ 689 1711]]\n",
      "================================================================================\n",
      "with_emoticon_nospelling_nolemma BOW-TF Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.74598214 0.76071429 0.75357143 0.76071429 0.74676195]\n",
      "Mean Training Accuracy: 0.7535488180310087\n",
      "Testing Accuracy: 0.75625\n",
      "Accuracy: 0.7562\n",
      "Precision: 0.7563\n",
      "Recall: 0.7562\n",
      "F1 Score: 0.7562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.75      0.76      2400\n",
      "    positive       0.75      0.76      0.76      2400\n",
      "\n",
      "    accuracy                           0.76      4800\n",
      "   macro avg       0.76      0.76      0.76      4800\n",
      "weighted avg       0.76      0.76      0.76      4800\n",
      "\n",
      "[[1807  593]\n",
      " [ 577 1823]]\n",
      "================================================================================\n",
      "with_emoticon_nospelling_nolemma BOW-TF Support Vector Machines\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.74285714 0.74821429 0.73392857 0.75178571 0.7284502 ]\n",
      "Mean Training Accuracy: 0.7410471830536591\n",
      "Testing Accuracy: 0.7470833333333333\n",
      "Accuracy: 0.7471\n",
      "Precision: 0.7472\n",
      "Recall: 0.7471\n",
      "F1 Score: 0.7471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.76      0.75      2400\n",
      "    positive       0.75      0.74      0.74      2400\n",
      "\n",
      "    accuracy                           0.75      4800\n",
      "   macro avg       0.75      0.75      0.75      4800\n",
      "weighted avg       0.75      0.75      0.75      4800\n",
      "\n",
      "[[1815  585]\n",
      " [ 629 1771]]\n",
      "================================================================================\n",
      "with_emoticon_nospelling_nolemma BOW-TFIDF Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.74553571 0.74955357 0.74732143 0.75625    0.74050916]\n",
      "Mean Training Accuracy: 0.7478339740317744\n",
      "Testing Accuracy: 0.7564583333333333\n",
      "Accuracy: 0.7565\n",
      "Precision: 0.757\n",
      "Recall: 0.7565\n",
      "F1 Score: 0.7563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.78      0.76      2400\n",
      "    positive       0.77      0.73      0.75      2400\n",
      "\n",
      "    accuracy                           0.76      4800\n",
      "   macro avg       0.76      0.76      0.76      4800\n",
      "weighted avg       0.76      0.76      0.76      4800\n",
      "\n",
      "[[1868  532]\n",
      " [ 637 1763]]\n",
      "================================================================================\n",
      "with_emoticon_nospelling_nolemma BOW-TFIDF Support Vector Machines\n",
      "--------------------------------------------------------------------------------\n",
      "Training Accuracy (5-fold): [0.74285714 0.75803571 0.74866071 0.75892857 0.74810183]\n",
      "Mean Training Accuracy: 0.7513167948063548\n",
      "Testing Accuracy: 0.7535416666666667\n",
      "Accuracy: 0.7535\n",
      "Precision: 0.7546\n",
      "Recall: 0.7535\n",
      "F1 Score: 0.7533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.79      0.76      2400\n",
      "    positive       0.77      0.72      0.75      2400\n",
      "\n",
      "    accuracy                           0.75      4800\n",
      "   macro avg       0.75      0.75      0.75      4800\n",
      "weighted avg       0.75      0.75      0.75      4800\n",
      "\n",
      "[[1887  513]\n",
      " [ 670 1730]]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=random_state, solver='lbfgs')\n",
    "\n",
    "# Support Vector Machines\n",
    "svm = LinearSVC(penalty='l2', max_iter=10000, C=1, random_state=random_state)\n",
    "\n",
    "datasets = ['without_emoticon', 'with_emoticon', 'with_emoticon_nospelling_nolemma']\n",
    "supervised_learning_models = {'Logistic Regression':lr, 'Support Vector Machines':svm}\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dataset_filename = 'training_16000_cleaned_' + dataset + '.csv'\n",
    "    \n",
    "    df = pd.read_csv('../data/' + dataset_filename, encoding='ISO-8859-1')\n",
    "    df.loc[df['polarity'] == 0, 'polarity'] = 'negative'\n",
    "    df.loc[df['polarity'] == 4, 'polarity'] = 'positive'\n",
    "    \n",
    "    train_corpus, test_corpus, train_label, test_label = train_test_split(np.array(df['cleaned_tweet']),\n",
    "                                                                            np.array(df['polarity']),                                                                                                                        \n",
    "                                                                            test_size=0.30, \n",
    "                                                                            shuffle=True,\n",
    "                                                                            random_state=random_state,\n",
    "                                                                            stratify=df['polarity'])\n",
    "    \n",
    "    # build BOW features    \n",
    "    bow_tf = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "    bow_tf_train_features = bow_tf.fit_transform(train_corpus)\n",
    "    bow_tf_test_features = bow_tf.transform(test_corpus)\n",
    "\n",
    "    # build TFIDF features\n",
    "    bow_tfidf = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "    bow_tfidf_train_features = bow_tfidf.fit_transform(train_corpus)\n",
    "    bow_tfidf_test_features = bow_tfidf.transform(test_corpus)\n",
    "    \n",
    "    feature_engineering_models = {'BOW-TF':{'train':bow_tf_train_features, 'test':bow_tf_test_features},\n",
    "                                  'BOW-TFIDF':{'train':bow_tfidf_train_features, 'test':bow_tfidf_test_features}}\n",
    "    \n",
    "    for fg_key in feature_engineering_models.keys():\n",
    "        \n",
    "        for sl_key in supervised_learning_models.keys():\n",
    "            \n",
    "            print('{} {} {}'.format(dataset, fg_key, sl_key))\n",
    "            print('-' * 80)\n",
    "            \n",
    "            classify(supervised_learning_models[sl_key], feature_engineering_models[fg_key]['train'], train_label, feature_engineering_models[fg_key]['test'], test_label)\n",
    "            \n",
    "            print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing ended at 2023-04-04 20:42:13.909208\n"
     ]
    }
   ],
   "source": [
    "print('Text processing ended at {}'.format(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
