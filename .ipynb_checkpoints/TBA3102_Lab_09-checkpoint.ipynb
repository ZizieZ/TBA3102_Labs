{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c0b2ea-3bd2-46f8-a35c-cadc47001f74",
   "metadata": {},
   "source": [
    "# TBA 3102 - Text Analytics\n",
    "## Practical Lab 09 - Text Summarization and Topic Models (II)\n",
    "### Question 1 - Topic Modeling\n",
    "Student: Nicky Ng <br>\n",
    "GitHub User: [ahjimomo](https://github.com/ahjimomo) <br>\n",
    "Student Number: A0194330L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196b720-e697-42ff-8be2-c42abf5aad6d",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e8bd4-8abe-493c-aca5-c5ce84c3f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Topic Modeling\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "# Tokenizer & Feature Engineering\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "# Gemsim models\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "\n",
    "# Parameters Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid\n",
    "\n",
    "# Display DF\n",
    "from IPython.core.display import HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc247c8-8b6d-44d0-b6d0-7039fae00ee6",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0777201-efde-4e54-b77e-74b073dc95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned dataset\n",
    "raw_df = pd.read_csv('./data/voted-kaggled-dataset-cleaned.csv')\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3c356-1002-4ee3-a035-bf5f04f8ab03",
   "metadata": {},
   "source": [
    "### Feature Engineering to prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432d675-9c96-4e76-a22d-b52d50a4f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(descriptions):\n",
    "    \n",
    "    norm_description = []\n",
    "    \n",
    "    for description in descriptions:\n",
    "        \n",
    "        desc_tokens = [token.strip() for token in wtk.tokenize(description)]    \n",
    "        desc_tokens = [wnl.lemmatize(token) for token in desc_tokens if not token.isnumeric()]\n",
    "        desc_tokens = [token for token in desc_tokens if len(token) > 1]\n",
    "        desc_tokens = [token for token in desc_tokens if token not in stop_words]\n",
    "        desc_tokens = list(filter(None, desc_tokens))\n",
    "        \n",
    "        norm_description.append(desc_tokens)\n",
    "    \n",
    "    return norm_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3a618-6154-4abf-8912-1894c9a18db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_desc = list(raw_df['Cleaned_Description'])\n",
    "norm_desc = normalize_corpus(processed_desc)\n",
    "raw_df['normalized_description'] = norm_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d9ea2-5967-4162-b7bd-2074bdb892d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063027ee-cfde-4827-bba3-fa354181ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Cleaning\n",
    "#bigram = gensim.models.Phrases(raw_df['normalized_description'], min_count = 20, threshold = 20, delimiter  = '_')\n",
    "#bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "# Creating both unigram & bigram\n",
    "#norm_corpus = []\n",
    "#for doc in raw_df['normalized_description']:\n",
    "#    bigram_doc = bigram_model[doc]\n",
    "#    norm_corpus.append(bigram_doc)\n",
    "#print(bigram_doc)\n",
    "\n",
    "# Create a dictionary representation of the document of unigram\n",
    "dictionary = gensim.corpora.Dictionary(norm_desc)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 60% of the documents.\n",
    "dictionary.filter_extremes(no_below = 20, no_above = 0.6)\n",
    "\n",
    "# Transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3984ba3-ceb3-4ed5-bd36-d0bcb564431b",
   "metadata": {},
   "source": [
    "### fine-tuning & selecting optimal algorithm and model\n",
    "* Latent Semantic Indexing: [LSI Parameters] (https://radimrehurek.com/gensim/models/lsimodel.html)\n",
    "* Latent Dirichlet Allocation: [LDA parameters] (https://radimrehurek.com/gensim/models/ldamodel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d4cb6-b666-4a6a-afd2-abb949163b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_model(corpus, dictionary, algor, df):\n",
    "    # Initialize dataframe and list to store results\n",
    "    results = pd.DataFrame()\n",
    "    coherence_cv_scores = []\n",
    "    coherence_UMass_scores = []\n",
    "    parameters = []\n",
    "    algor_lst = []\n",
    "    \n",
    "    # Parameters\n",
    "    topic_lst = [5, 6, 7, 8, 9, 10]\n",
    "    random_seed = [42]\n",
    "    \n",
    "    # Compute hyperparameter grid\n",
    "    if algor == 'LSI':\n",
    "        hyperparams = {'num_topics': topic_lst, 'random_seed': random_seed, 'power_iters': [10, 50, 100]}\n",
    "    elif algor == 'LDA':\n",
    "        hyperparams = {'num_topics': topic_lst, 'random_state': random_seed, 'alpha': ['symmetric', 'auto'], 'passes': [1, 10], 'iterations': [50, 200]}\n",
    "    paramgrid = list(ParameterGrid(hyperparams))\n",
    "    \n",
    "    # Loop over parameter grid for LSI\n",
    "    count = 0\n",
    "    for params in paramgrid:\n",
    "        if algor == 'LSI':\n",
    "            model = LsiModel(corpus = corpus, id2word = dictionary, **params)\n",
    "        elif algor == 'LDA':\n",
    "            model = LdaModel(corpus = corpus, id2word = dictionary, **params)\n",
    "        \n",
    "        # Compute coherence score\n",
    "        umass_model = CoherenceModel(model = model, corpus = corpus, dictionary = dictionary, coherence = 'u_mass')\n",
    "        umass_score = umass_model.get_coherence()\n",
    "        cv_model = CoherenceModel(model = model, texts = df['normalized_description'], dictionary = dictionary, coherence = 'c_v')\n",
    "        cv_score = cv_model.get_coherence()\n",
    "        \n",
    "        # Store the results\n",
    "        algor_lst.append(f'{algor}_{count}')\n",
    "        parameters.append(params)\n",
    "        coherence_cv_scores.append(cv_score)\n",
    "        coherence_UMass_scores.append(umass_score)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    # Append result to result dataframe and return dataframe\n",
    "    results['algorithm'] = algor_lst\n",
    "    results['cv_score'] = coherence_cv_scores\n",
    "    results['umass_score'] = coherence_UMass_scores\n",
    "    results['parameters'] = parameters\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f51560-7943-4fba-94d5-f57cbd4875a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Topic Modeling with LSI\n",
    "LSI_results = finetuning_model(bow_corpus, dictionary, 'LSI', raw_df)\n",
    "LSI_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ff9f0-ed4a-4da5-a467-254d99983481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Topic Modeling with LDA\n",
    "LDA_results = finetuning_model(bow_corpus, dictionary, 'LDA', raw_df)\n",
    "LDA_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5dcca6-9319-406e-b73b-c67c87ba721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat results together\n",
    "full_results = pd.concat([LSI_results, LDA_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659be3b-6718-4fbf-93d3-a29cb82f9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41509b8-a27b-4bda-958c-2f2d3fe1af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange results\n",
    "results = full_results.sort_values('umass_score', ascending = True).sort_values('cv_score', ascending = False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c8e7b-c114-4bca-8740-a9402eab12b2",
   "metadata": {},
   "source": [
    "Using perplexity and coherence scores as measures to evaluate the topic model, the model would be better if\n",
    "- Lower the UMass score\n",
    "- Higher the Cv score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920632b-6cea-4c54-a257-fa6e41f8d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b044b8e-5b56-4430-92a2-3d837b4a86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4887c-b8f8-4af9-a54c-50b8633ef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4c. Determine the most dominant topic for each document using the best model\n",
    "best_model = LdaModel(corpus = bow_corpus, id2word = dictionary, alpha = 'symmetric',\n",
    "                      iterations = 50, num_topics = 5, passes = 10,\n",
    "                      random_state = 42)\n",
    "\n",
    "# Compute dominant topics for each document\n",
    "topic_weights = []\n",
    "for row in best_model[bow_corpus]:\n",
    "    topic_weights.append(dict(row))\n",
    "    \n",
    "topic_weights_df = pd.DataFrame(topic_weights)\n",
    "\n",
    "# List to store topic and keywords\n",
    "dominant_topics = []\n",
    "topic_keywords = []\n",
    "\n",
    "for i, row in topic_weights_df.iterrows():\n",
    "    sorted_topics = sorted(row.items(), key = lambda x: x[1], reverse = True)\n",
    "    top_topic = f\"Topic {sorted_topics[0][0]} ({sorted_topics[0][1]:.3f})\"\n",
    "    dominant_topics.append(top_topic)\n",
    "    \n",
    "    # Get top keywords for each topic\n",
    "    keywords = [word for (word, prob) in best_model.show_topic(sorted_topics[0][0], topn=10)]\n",
    "    topic_keywords.append(keywords)\n",
    "    \n",
    "# Append topic back to dataframe\n",
    "final_df['Dominant_Topic'] = dominant_topics\n",
    "final_df['Topic_Keywords'] = topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f6643-5259-4ce8-899f-5eb26c93bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['Cleaned_Description', 'Dominant_Topic', 'Topic_Keywords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54e73f-7f2b-4ae9-9137-00a93d62a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./data/corupus_topic_best.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
