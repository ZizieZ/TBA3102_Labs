{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import textblob\n",
    "from afinn import Afinn\n",
    "import spacy\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import tba3102\n",
    "import model_evaluation_utils as meu\n",
    "\n",
    "\n",
    "\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "tba3102.set_default_pandas_options()\n",
    "\n",
    "afn = Afinn(emoticons=True)\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_sentiwordnet_lexicon(text, verbose=False):\n",
    "\n",
    "    # tokenize and POS tag text tokens\n",
    "    tagged_text = [(token.text, token.tag_) for token in nlp(text)]\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "\n",
    "        # if senti-synset is found\n",
    "        if ss_set:\n",
    "\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "\n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    \n",
    "    if token_count != 0:\n",
    "        \n",
    "        norm_final_score = round(float(final_score) / token_count, 2)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        norm_final_score = final_score\n",
    "        \n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "\n",
    "        print('SENTIMENT STATS:')\n",
    "        print('Predicted Sentiment', final_sentiment)\n",
    "        print('Objectivity', norm_obj_score)\n",
    "        print('Positive', norm_pos_score)\n",
    "        print('Negative', norm_neg_score)\n",
    "        print('Overall', norm_final_score)\n",
    "\n",
    "    return final_sentiment\n",
    "\n",
    "\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(text, threshold=0.1, verbose=False):\n",
    "\n",
    "    # analyze the sentiment for text\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold else 'negative'\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "\n",
    "        print('SENTIMENT STATS:')\n",
    "        print('Predicted Sentiment', final_sentiment)\n",
    "        print('Polarity Score', final)\n",
    "        print('Positive', positive)\n",
    "        print('Negative', negative)\n",
    "        print('Neutral', neutral)\n",
    "\n",
    "    return final_sentiment\n",
    "\n",
    "\n",
    "\n",
    "def lexicon_sentiment_analysis(dataset_name, df, column_name_text, column_name_actual_sentiment, lexicon):\n",
    "    \n",
    "    sentiment_polarity = []\n",
    "    predicted_sentiments = []\n",
    "    \n",
    "    print('Lexicon-based Sentiment Analysis: {} with {}'.format(dataset_name, lexicon))\n",
    "    print('-' * 80)\n",
    "    \n",
    "    if lexicon == 'textblob':\n",
    "        \n",
    "        sentiment_polarity = [textblob.TextBlob(text).sentiment.polarity for text in df[column_name_text].array]\n",
    "        predicted_sentiments = ['positive' if score >= 0.1 else 'negative' for score in sentiment_polarity]\n",
    "        \n",
    "    elif lexicon == 'afinn':\n",
    "        \n",
    "        sentiment_polarity = [afn.score(text) for text in df[column_name_text].array]\n",
    "        predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in sentiment_polarity]\n",
    "    \n",
    "    elif lexicon == 'sentiwordnet':\n",
    "                \n",
    "        predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(text, verbose=False) for text in df[column_name_text].array]\n",
    "        \n",
    "    elif lexicon == 'vader':\n",
    "        \n",
    "        predicted_sentiments = [analyze_sentiment_vader_lexicon(text, verbose=False) for text in df[column_name_text].array]\n",
    "    \n",
    "        \n",
    "    meu.get_metrics(true_labels=df[column_name_actual_sentiment].array, predicted_labels=predicted_sentiments)\n",
    "    meu.display_classification_report(true_labels=df[column_name_actual_sentiment].array, predicted_labels=predicted_sentiments, \n",
    "                                      classes=['positive', 'negative'])\n",
    "    print(metrics.confusion_matrix(y_true=df[column_name_actual_sentiment].array, y_pred=predicted_sentiments, labels=['positive', 'negative']))\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing started at 2023-04-04 20:39:38.621019\n"
     ]
    }
   ],
   "source": [
    "print('Text processing started at {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon-based Sentiment Analysis: without_emoticon with textblob\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6214\n",
      "Precision: 0.6303\n",
      "Recall: 0.6214\n",
      "F1 Score: 0.6149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.49      0.56      7998\n",
      "    negative       0.60      0.75      0.67      7996\n",
      "\n",
      "    accuracy                           0.62     15994\n",
      "   macro avg       0.63      0.62      0.61     15994\n",
      "weighted avg       0.63      0.62      0.61     15994\n",
      "\n",
      "[[3927 4071]\n",
      " [1984 6012]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: without_emoticon with afinn\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6351\n",
      "Precision: 0.6387\n",
      "Recall: 0.6351\n",
      "F1 Score: 0.6328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.56      0.60      7998\n",
      "    negative       0.62      0.71      0.66      7996\n",
      "\n",
      "    accuracy                           0.64     15994\n",
      "   macro avg       0.64      0.64      0.63     15994\n",
      "weighted avg       0.64      0.64      0.63     15994\n",
      "\n",
      "[[4441 3557]\n",
      " [2279 5717]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: without_emoticon with sentiwordnet\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6376\n",
      "Precision: 0.6485\n",
      "Recall: 0.6376\n",
      "F1 Score: 0.6307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.61      0.77      0.68      7998\n",
      "    negative       0.69      0.50      0.58      7996\n",
      "\n",
      "    accuracy                           0.64     15994\n",
      "   macro avg       0.65      0.64      0.63     15994\n",
      "weighted avg       0.65      0.64      0.63     15994\n",
      "\n",
      "[[6186 1812]\n",
      " [3985 4011]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: without_emoticon with vader\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6452\n",
      "Precision: 0.647\n",
      "Recall: 0.6452\n",
      "F1 Score: 0.6442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.59      0.63      7998\n",
      "    negative       0.63      0.70      0.66      7996\n",
      "\n",
      "    accuracy                           0.65     15994\n",
      "   macro avg       0.65      0.65      0.64     15994\n",
      "weighted avg       0.65      0.65      0.64     15994\n",
      "\n",
      "[[4729 3269]\n",
      " [2405 5591]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon with textblob\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6248\n",
      "Precision: 0.6331\n",
      "Recall: 0.6248\n",
      "F1 Score: 0.6188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.67      0.50      0.57      8000\n",
      "    negative       0.60      0.75      0.67      7999\n",
      "\n",
      "    accuracy                           0.62     15999\n",
      "   macro avg       0.63      0.62      0.62     15999\n",
      "weighted avg       0.63      0.62      0.62     15999\n",
      "\n",
      "[[3997 4003]\n",
      " [2000 5999]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon with afinn\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6367\n",
      "Precision: 0.6401\n",
      "Recall: 0.6367\n",
      "F1 Score: 0.6345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.56      0.61      8000\n",
      "    negative       0.62      0.71      0.66      7999\n",
      "\n",
      "    accuracy                           0.64     15999\n",
      "   macro avg       0.64      0.64      0.63     15999\n",
      "weighted avg       0.64      0.64      0.63     15999\n",
      "\n",
      "[[4470 3530]\n",
      " [2282 5717]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon with sentiwordnet\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6394\n",
      "Precision: 0.6502\n",
      "Recall: 0.6394\n",
      "F1 Score: 0.6328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.61      0.77      0.68      8000\n",
      "    negative       0.69      0.51      0.58      7999\n",
      "\n",
      "    accuracy                           0.64     15999\n",
      "   macro avg       0.65      0.64      0.63     15999\n",
      "weighted avg       0.65      0.64      0.63     15999\n",
      "\n",
      "[[6186 1814]\n",
      " [3955 4044]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon with vader\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6449\n",
      "Precision: 0.646\n",
      "Recall: 0.6449\n",
      "F1 Score: 0.6442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.60      0.63      8000\n",
      "    negative       0.63      0.69      0.66      7999\n",
      "\n",
      "    accuracy                           0.64     15999\n",
      "   macro avg       0.65      0.64      0.64     15999\n",
      "weighted avg       0.65      0.64      0.64     15999\n",
      "\n",
      "[[4812 3188]\n",
      " [2494 5505]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon_nospelling_nolemma with textblob\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6419\n",
      "Precision: 0.6482\n",
      "Recall: 0.6419\n",
      "F1 Score: 0.638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.68      0.54      0.60      7999\n",
      "    negative       0.62      0.75      0.68      8000\n",
      "\n",
      "    accuracy                           0.64     15999\n",
      "   macro avg       0.65      0.64      0.64     15999\n",
      "weighted avg       0.65      0.64      0.64     15999\n",
      "\n",
      "[[4308 3691]\n",
      " [2039 5961]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon_nospelling_nolemma with afinn\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.647\n",
      "Precision: 0.6496\n",
      "Recall: 0.647\n",
      "F1 Score: 0.6454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.67      0.58      0.62      7999\n",
      "    negative       0.63      0.71      0.67      8000\n",
      "\n",
      "    accuracy                           0.65     15999\n",
      "   macro avg       0.65      0.65      0.65     15999\n",
      "weighted avg       0.65      0.65      0.65     15999\n",
      "\n",
      "[[4650 3349]\n",
      " [2299 5701]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon_nospelling_nolemma with sentiwordnet\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6415\n",
      "Precision: 0.6539\n",
      "Recall: 0.6415\n",
      "F1 Score: 0.6341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.61      0.78      0.69      7999\n",
      "    negative       0.70      0.50      0.58      8000\n",
      "\n",
      "    accuracy                           0.64     15999\n",
      "   macro avg       0.65      0.64      0.63     15999\n",
      "weighted avg       0.65      0.64      0.63     15999\n",
      "\n",
      "[[6268 1731]\n",
      " [4005 3995]]\n",
      "================================================================================\n",
      "Lexicon-based Sentiment Analysis: with_emoticon_nospelling_nolemma with vader\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.6609\n",
      "Precision: 0.6614\n",
      "Recall: 0.6609\n",
      "F1 Score: 0.6606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.67      0.63      0.65      7999\n",
      "    negative       0.65      0.69      0.67      8000\n",
      "\n",
      "    accuracy                           0.66     15999\n",
      "   macro avg       0.66      0.66      0.66     15999\n",
      "weighted avg       0.66      0.66      0.66     15999\n",
      "\n",
      "[[5058 2941]\n",
      " [2484 5516]]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "datasets = ['without_emoticon', 'with_emoticon', 'with_emoticon_nospelling_nolemma']\n",
    "lexicons = ['textblob', 'afinn', 'sentiwordnet', 'vader']\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dataset_filename = 'training_16000_cleaned_' + dataset + '.csv'\n",
    "    \n",
    "    df = pd.read_csv('../data/' + dataset_filename, encoding='ISO-8859-1')\n",
    "    df.loc[df['polarity'] == 0, 'polarity'] = 'negative'\n",
    "    df.loc[df['polarity'] == 4, 'polarity'] = 'positive'        \n",
    "    \n",
    "    for lexicon in lexicons:\n",
    "        \n",
    "        lexicon_sentiment_analysis(dataset, df, 'cleaned_tweet', 'polarity', lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing ended at 2023-04-04 20:47:10.240434\n"
     ]
    }
   ],
   "source": [
    "print('Text processing ended at {}'.format(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
