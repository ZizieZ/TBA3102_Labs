{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing started at 2023-03-19 10:46:50.931787\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import tba3102\n",
    "\n",
    "\n",
    "\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "tba3102.set_default_pandas_options(max_columns=16, width=1500, max_colwidth=300)\n",
    "\n",
    "print('Text processing started at {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/voted-kaggle-dataset-cleaned.csv', index_col=0)\n",
    "documents = [tba3102.tokenize_sentence_to_words(cleaned_description) for cleaned_description in df['Cleaned_Description']]\n",
    "\n",
    "\n",
    "\n",
    "bigram = gensim.models.Phrases(documents, min_count=20, threshold=20, delimiter='_') # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "corpus_bigrams = [bigram_model[doc] for doc in documents]\n",
    "dictionary = gensim.corpora.Dictionary(corpus_bigrams)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in corpus_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'LDA'\n",
    "START_TOPIC_COUNT = 3\n",
    "END_TOPIC_COUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: LDA - NUMBER OF TOPICS: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.56s/it]\n"
     ]
    }
   ],
   "source": [
    "models, coherence_scores = tba3102.topic_model_coherence_generator(model_name = MODEL_NAME,\n",
    "                                                                    corpus=bow_corpus,\n",
    "                                                                    texts=corpus_bigrams,\n",
    "                                                                    dictionary=dictionary,\n",
    "                                                                    start_topic_count=START_TOPIC_COUNT,\n",
    "                                                                    end_topic_count=END_TOPIC_COUNT,\n",
    "                                                                    step=1,\n",
    "                                                                    cpus=-1,\n",
    "                                                                    print_topics=False)\n",
    "model = models[0]\n",
    "\n",
    "topics = [[(term, round(wt, 3))\n",
    "                for term, wt in model.show_topic(n, topn=7)]\n",
    "                    for n in range(0, model.num_topics)]\n",
    "\n",
    "topics_df = pd.DataFrame([[term for term, wt in topic]\n",
    "                            for topic in topics],\n",
    "                        columns = ['Term'+str(i) for i in range(1, 8)],\n",
    "                        index=['Topic '+str(t) for t in range(1, model.num_topics+1)]).T\n",
    "\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])\n",
    "                                for topic in topics],\n",
    "                                columns = ['Terms per Topic'],\n",
    "                                index=['Topic'+str(t) for t in range(1, model.num_topics+1)])\n",
    "\n",
    "tm_results = model[bow_corpus]\n",
    "\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in tm_results]\n",
    "\n",
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(documents))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Document'] = documents\n",
    "\n",
    "corpus_topic_df.to_csv('../data/corpus_topic_best.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing ended at 2023-03-19 10:47:02.458697\n"
     ]
    }
   ],
   "source": [
    "print('Text processing ended at {}'.format(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
